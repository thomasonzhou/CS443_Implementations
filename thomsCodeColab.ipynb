{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74ef19e5289e460d8fffc7e4fc65fe77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a1093d45b6d4b9885358d9c2fd194fa",
              "IPY_MODEL_047159ead46f4b68b808406f4c2b2ad6",
              "IPY_MODEL_d3dd3721f24b4de096a6cfb2646157e8"
            ],
            "layout": "IPY_MODEL_8a46ce8796b44e289bc3659430242713"
          }
        },
        "8a1093d45b6d4b9885358d9c2fd194fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61691e6ad2dc46a289e85c8095aca316",
            "placeholder": "​",
            "style": "IPY_MODEL_6de1b06f57fb4afbb8b9b92bec82cde4",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "047159ead46f4b68b808406f4c2b2ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fe0a44815a8469188733c633c07d423",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a72de5e63084402bbadf34b05d22cb1a",
            "value": 2
          }
        },
        "d3dd3721f24b4de096a6cfb2646157e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8f7ff90d7147cba37e2dd9fdae665d",
            "placeholder": "​",
            "style": "IPY_MODEL_7a051e50ff21406abe60e5b82d23addf",
            "value": " 2/2 [00:00&lt;00:00, 15.44it/s]"
          }
        },
        "8a46ce8796b44e289bc3659430242713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "61691e6ad2dc46a289e85c8095aca316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de1b06f57fb4afbb8b9b92bec82cde4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fe0a44815a8469188733c633c07d423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72de5e63084402bbadf34b05d22cb1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf8f7ff90d7147cba37e2dd9fdae665d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a051e50ff21406abe60e5b82d23addf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5aa3b65b72174126970621c8e1941be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ed54a700a824facb72c443cfdc6e6f5",
              "IPY_MODEL_424827fa93a14875a9f429c9d0c81b04",
              "IPY_MODEL_b4a2db8a4a7d49c193a6cfec76d7b140"
            ],
            "layout": "IPY_MODEL_ba401e22ce37456591305c475f89a9d6"
          }
        },
        "1ed54a700a824facb72c443cfdc6e6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be4681cdf34468da0ec87f717b066cf",
            "placeholder": "​",
            "style": "IPY_MODEL_7e9d582ddb5047019d7abea8342907c1",
            "value": "Epoch 0:   1%"
          }
        },
        "424827fa93a14875a9f429c9d0c81b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696eb13323f244b3a5580f569263a1cf",
            "max": 6400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecd04956bbd1493682f7dac62bed1f44",
            "value": 80
          }
        },
        "b4a2db8a4a7d49c193a6cfec76d7b140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6703ba0fd014953b8cab298951f1b47",
            "placeholder": "​",
            "style": "IPY_MODEL_9a5b38489ef643ff930d84ea1fd59438",
            "value": " 80/6400 [00:38&lt;50:18,  2.09it/s, v_num=0, train_loss=0.757]"
          }
        },
        "ba401e22ce37456591305c475f89a9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2be4681cdf34468da0ec87f717b066cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e9d582ddb5047019d7abea8342907c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "696eb13323f244b3a5580f569263a1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd04956bbd1493682f7dac62bed1f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6703ba0fd014953b8cab298951f1b47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a5b38489ef643ff930d84ea1fd59438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomasonzhou/CS443_Implementations/blob/master/thomsCodeColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AA4QiJNUh-F",
        "outputId": "f394b72c-aa48-4ed5-91fc-b4ea1df08770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/fingerprints_combined\")\n",
        "# os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMG_DIR = \"/content/drive/My Drive/fingerprints_combined\"\n",
        "\n",
        "\n",
        "def print_data_info():\n",
        "    files = os.listdir(IMG_DIR)\n",
        "    fvc_names = [name for name in files if \"FVC\" in name]\n",
        "    uareu_names = [name for name in files if \"UareU\" in name]\n",
        "    fv_system_names = [name for name in files if \"fingerprint\" in name]\n",
        "    print(f\"{len(fvc_names)/8} Fingerprint verification competition\")\n",
        "    print(f\"{len(uareu_names)/8} U.are.U\")\n",
        "    print(f\"{len(fv_system_names)/8} Fingerprint verification system\")\n",
        "    print(f\"{len(files)} Files\")\n",
        "\n",
        "\n",
        "def show_visualization_samples(dataset, count=4):\n",
        "    fig = plt.figure()\n",
        "\n",
        "    for i, (sample1, sample2, same_label) in enumerate(dataset):\n",
        "\n",
        "        ax = plt.subplot(2, count, i + 1)\n",
        "        # plt.tight_layout()\n",
        "        ax.set_title(f'{same_label[0]}')\n",
        "        ax.axis('off')\n",
        "\n",
        "        # change to black and white\n",
        "        plt.imshow(sample1.squeeze(), cmap=\"gray\")\n",
        "        # plt.imshow(sample.permute(1, 2, 0))\n",
        "\n",
        "        ax = plt.subplot(2, count, i + 1 + count)\n",
        "        plt.imshow(sample2.squeeze(), cmap=\"gray\")\n",
        "        ax.axis('off')\n",
        "\n",
        "        if i == count - 1:\n",
        "            plt.show()\n",
        "            break\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print_data_info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_xQckQwVJO4",
        "outputId": "0672ccf7-6abf-4c7a-b761-d32524ce05d3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1320.0 Fingerprint verification competition\n",
            "65.0 U.are.U\n",
            "21.0 Fingerprint verification system\n",
            "11248 Files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsH6wrz8V1Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class FingerprintDataset(Dataset):\n",
        "\n",
        "    #script_dir = os.path.dirname(__file__)\n",
        "    script_dir = os.path.dirname(IMG_DIR)\n",
        "\n",
        "    def __init__(self, train=True, transform=None):\n",
        "        file_path = os.path.join(self.script_dir, \"metadata.csv\")\n",
        "        self.csv = pd.read_csv(file_path)\n",
        "\n",
        "        if train:\n",
        "            self.csv = self.csv[self.csv[\"test_set\"] == False]\n",
        "        else:\n",
        "            self.csv = self.csv[self.csv[\"test_set\"] == True]#removes condition for all se\n",
        "        self.transform = transform\n",
        "        # print(self.csv.columns)\n",
        "        # ['dataset', 'original_filename', 'person_id', 'impression_id', 'finger_id', 'fileextension', 'db_id', 'filename', 'test_set']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)\n",
        "        return\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.to_list()\n",
        "\n",
        "        # potentially invert the image\n",
        "\n",
        "        get_same_class = torch.rand(1) < 0.5\n",
        "\n",
        "        img1_name, img2_name = self.get_pair_names(idx, get_same_class)\n",
        "\n",
        "        img1_path = os.path.join(\"./fingerprints_combined\", img1_name)\n",
        "        img2_path = os.path.join(\"./fingerprints_combined\", img2_name)\n",
        "\n",
        "        # L is for black and white, RGB is for color\n",
        "        image1 = Image.open(img1_path).convert(\"L\")\n",
        "        image2 = Image.open(img2_path).convert(\"L\")\n",
        "\n",
        "        if self.transform:\n",
        "            image1 = self.transform(image1)\n",
        "            image2 = self.transform(image2)\n",
        "\n",
        "        # print(get_same_class)\n",
        "        # print(self.csv.iloc[idx, -2], class_sample.iloc[0, -2])\n",
        "\n",
        "        label = 1 if get_same_class else 0\n",
        "        return image1, image2, label\n",
        "\n",
        "    def get_pair_names(self, idx, get_same_class=True):\n",
        "\n",
        "        img1_name = self.csv.iloc[idx, -2]\n",
        "\n",
        "        person_id = self.csv.iloc[idx, 2]\n",
        "\n",
        "        # indexing for impressions, UareU has an extra column\n",
        "        finger_idx = 4 if self.csv.iloc[idx, 0] == \"UareU\" else 2\n",
        "        finger_id = self.csv.iloc[idx, finger_idx]\n",
        "\n",
        "        # don't compare the same file with itself\n",
        "        different_file = self.csv.loc[(self.csv.iloc[:, -2] != img1_name)]\n",
        "\n",
        "        if get_same_class:\n",
        "            # FVC2000, 2002, 2004 are different\n",
        "            same_dataset = different_file[(\n",
        "                different_file.iloc[:, 0] == self.csv.iloc[idx, 0])]\n",
        "\n",
        "            # DB 1, 2, 3, 4 are different for FVC (additional processing)\n",
        "            if \"FVC\" in self.csv.iloc[idx, 0]:\n",
        "\n",
        "                # get the DB number from the filename\n",
        "                # e.g. FVC2002-DB1_A-50_6.tif\n",
        "                db_id = self.csv.iloc[idx, -3]\n",
        "\n",
        "                same_dataset = same_dataset[(\n",
        "                    same_dataset.iloc[:, -3] == db_id)]\n",
        "\n",
        "            same_finger = same_dataset[(\n",
        "                same_dataset.iloc[:, finger_idx] == finger_id)]\n",
        "\n",
        "            if self.csv.iloc[idx, 0] == \"UareU\":\n",
        "                # filter by person id\n",
        "                same_finger = same_finger.loc[(\n",
        "                    same_finger.iloc[:, 2] == person_id)]\n",
        "\n",
        "            # print(f\"same_count {len(same_finger)}\")\n",
        "            class_sample = same_finger.sample(n=1)\n",
        "        else:\n",
        "            different_class = different_file[(\n",
        "                different_file.iloc[:, finger_idx] != finger_id)]\n",
        "\n",
        "            if self.csv.iloc[idx, 0] == \"UareU\":\n",
        "                # filter by person id\n",
        "                different_class = different_class[(\n",
        "                    self.csv.iloc[:, 2] != person_id)]\n",
        "\n",
        "            # print(f\"different_count {len(different_class)}\")\n",
        "            class_sample = different_class.sample(n=1)\n",
        "\n",
        "        img2_name = class_sample.iloc[0, -2]\n",
        "\n",
        "        return img1_name, img2_name\n",
        "\n"
      ],
      "metadata": {
        "id": "sTf6Q9ZQUs5y"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "#from data_loading import FingerprintDataset\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "This script needs to be run from the model_evaluation folder.\n",
        "\"\"\"\n",
        "\n",
        "#assert os.path.isfile(\"./testset.csv\") == False, \"File already exists, do not overwrite.\"\n",
        "\n",
        "# generate new csv with test set, equal number of same and different fingerprint pairs\n",
        "# generate 1000 pairs, 500 same, 500 different\n",
        "NUMBER_OF_PAIRS = 1000\n",
        "HALF_PAIRS = NUMBER_OF_PAIRS // 2\n",
        "\n",
        "test_data = FingerprintDataset(train=False)\n",
        "print(f\"Test data: {len(test_data)}\")\n",
        "\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "\n",
        "df = pd.DataFrame(columns=[\"img1_name\", \"img2_name\", \"same_class\"])\n",
        "\n",
        "for i in range(HALF_PAIRS):\n",
        "    image1, image2, = test_data.get_pair_names(i, get_same_class=True)\n",
        "    df.loc[i] = [image1, image2, 1]\n",
        "for i in range(HALF_PAIRS):\n",
        "    image1, image2, = test_data.get_pair_names(i, get_same_class=False)\n",
        "    df.loc[i + HALF_PAIRS] = [image1, image2, 0]\n",
        "\n",
        "\n",
        "df.to_csv(\"./testset.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WAlPIbvVAXd",
        "outputId": "351b2fe5-69c6-47ab-d2ce-5ba5ca22f4c9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data: 960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ysp_oc1LW_tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Given the outputs of two identical sister networks, return the loss\n",
        "\n",
        "    References:\n",
        "    https://github.com/delijati/pytorch-siamese/blob/master/contrastive.py\n",
        "    https://hackernoon.com/facial-similarity-with-siamese-networks-in-pytorch-9642aa9db2f7?ref=hackernoon.com\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def check_valid_inputs():\n",
        "        pass\n",
        "\n",
        "    def forward(self, x1, x2, y):\n",
        "\n",
        "        # euclidean distance\n",
        "        diff = x1 - x2\n",
        "        dist_sq = torch.sum(torch.square(diff), dim=1)\n",
        "        dist = torch.sqrt(dist_sq)\n",
        "        # assert dist == torch.cdist(x1, x2)\n",
        "\n",
        "        mdist = self.margin - dist\n",
        "        clamp_mdist = torch.clamp(mdist, min=0)\n",
        "        clamp_mdist_sq = torch.square(clamp_mdist)\n",
        "\n",
        "        loss = (1-y)*0.5*dist_sq + y*0.5*clamp_mdist_sq\n",
        "        return torch.mean(loss)\n"
      ],
      "metadata": {
        "id": "lzpb6sN5W2Uy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FjgReVL7W2eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "#from data_loading import FingerprintDataset\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "This script needs to be run from the model_evaluation folder.\n",
        "\"\"\"\n",
        "\n",
        "#assert os.path.isfile(\"./testset.csv\") == False, \"File already exists, do not overwrite.\"\n",
        "\n",
        "# generate new csv with test set, equal number of same and different fingerprint pairs\n",
        "# generate 1000 pairs, 500 same, 500 different\n",
        "NUMBER_OF_PAIRS = 1000\n",
        "HALF_PAIRS = NUMBER_OF_PAIRS // 2\n",
        "\n",
        "test_data = FingerprintDataset(train=False)\n",
        "print(f\"Test data: {len(test_data)}\")\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "\n",
        "df = pd.DataFrame(columns=[\"img1_name\", \"img2_name\", \"same_class\"])\n",
        "\n",
        "for i in range(HALF_PAIRS):\n",
        "    image1, image2, = test_data.get_pair_names(i, get_same_class=True)\n",
        "    df.loc[i] = [image1, image2, 1]\n",
        "for i in range(HALF_PAIRS):\n",
        "    image1, image2, = test_data.get_pair_names(i, get_same_class=False)\n",
        "    df.loc[i + HALF_PAIRS] = [image1, image2, 0]\n",
        "\n",
        "\n",
        "df.to_csv(\"./testset.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6921asdHVA0i",
        "outputId": "63ac58ac-6b78-44bb-b052-f22ad35e2a8e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data: 960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class TorchSiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchSiameseNetwork, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, kernel_size=3, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(4, 8, kernel_size=3, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(512, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(500, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(500, 5),\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        output = self.cnn(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.mlp(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2\n"
      ],
      "metadata": {
        "id": "IM_Fwk0tWzSR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TorchVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchVGG, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2)\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 5)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        output = self.cnn(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.mlp(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "HJLnU4Lu1RWZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "#from data_loading import FingerprintDataset, show_visualization_samples\n",
        "from torch.utils.data import DataLoader\n",
        "#from models import ContrastiveLoss, TorchVGG\n",
        "from torch.optim import Adam\n",
        "#import my_transforms\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = FingerprintDataset(train=True, transform=transform)\n",
        "test_data = FingerprintDataset(train=False, transform=transform)\n",
        "\n",
        "print(f\"Train data: {len(train_data)}\")\n",
        "print(f\"Test data: {len(test_data)}\")\n",
        "# show_visualization_samples(test_data, count=5)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "\n",
        "# model = TorchSiameseNetwork()\n",
        "model = TorchVGG()\n",
        "# criterion = ContrastiveLoss(margin=1.0)\n",
        "criterion = nn.functional.binary_cross_entropy_with_logits(preds, y.float())\n",
        "optimizer = Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "# Training\n",
        "\n",
        "EPOCHS = 1\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "LOAD_SAVED_MODEL = True\n",
        "SAVED_MODEL_PATH = \"torch_cnn_transform3_lr22.pt\"\n",
        "\n",
        "losses = []\n",
        "\n",
        "#if LOAD_SAVED_MODEL and os.path.exists(SAVED_MODEL_PATH):\n",
        "#    model.load_state_dict(torch.load(SAVED_MODEL_PATH))\n",
        "#    print(\"Loaded saved model\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    for i, (image1, image2, same_class) in enumerate(train_loader, start=1):\n",
        "        image1, image2, same_class = image1.to(\n",
        "            device), image2.to(device), same_class.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x1, x2 = model(image1, image2)\n",
        "\n",
        "        loss = criterion(x1, x2, same_class)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Epoch {epoch} iteration {i} loss: {loss}\")\n",
        "            losses.append(loss.item())\n",
        "\n",
        "# rename original model and save as prev\n",
        "#if os.path.isfile(SAVED_MODEL_PATH):\n",
        "#    os.rename(SAVED_MODEL_PATH, \"./models/saved_parameters/torch_cnn_transform3_lr22_prev.pt\")\n",
        "\n",
        "# save new model\n",
        "torch.save(model.state_dict(),  SAVED_MODEL_PATH)\n",
        "\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "test_iter = iter(test_loader)\n",
        "# image1, _, _ = next(test_iter)\n",
        "\n",
        "# even number of samples please\n",
        "SAMPLES = 20\n",
        "\n",
        "fig, axes = plt.subplots(2, SAMPLES//2, figsize=(SAMPLES*2, 8))\n",
        "axes = axes.flatten()\n",
        "for i in range(SAMPLES):\n",
        "    image1, image2, label = next(test_iter)\n",
        "    concatenated = torch.cat((image1, image2), 3)\n",
        "\n",
        "    image1, image2, label = image1.to(\n",
        "        device), image2.to(device), label.to(device)\n",
        "\n",
        "    x1, x2 = model(image1, image2)\n",
        "\n",
        "    dist = torch.nn.functional.pairwise_distance(x1, x2)\n",
        "    # loss = criterion(x1, x2, label)\n",
        "\n",
        "    concatenated = concatenated.squeeze().cpu().numpy()\n",
        "\n",
        "    ax = axes[i]\n",
        "    ax.imshow(concatenated, cmap='gray')\n",
        "    ax.set_title(\n",
        "        f\"Dist: {dist.item():.2f} {True if label.item() else False}\")\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "ZeYAtdlCXVi5",
        "outputId": "09a1ea32-32c1-4579-a2ce-d74ccd85ce98"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 10288\n",
            "Test data: 960\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-606298c4622f>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchVGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# criterion = ContrastiveLoss(margin=1.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TorchVGG(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchVGG, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2)\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128,  128)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        output = self.cnn(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.mlp(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "VV0FlbiCXmVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# references:\n",
        "# https://datahacker.rs/019-siamese-network-in-pytorch-with-application-to-face-similarity/\n",
        "# https://github.com/pytorch/examples/blob/main/siamese_network/main.py\n",
        "\n",
        "import torchvision\n",
        "\n",
        "# create the Siamese Neural Network\n",
        "class SiameseNetwork_MobileNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork_MobileNet, self).__init__()\n",
        "\n",
        "        # load mobile net architecture (not pre-trained weights)\n",
        "        self.feature_extractor = torchvision.models.mobilenet_v3_small()\n",
        "        # modify input layer\n",
        "        self.feature_extractor.features[0][0] = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
        "        # modify output layer\n",
        "        self.feature_extractor.classifier[3] = nn.Linear(1024, 256)\n",
        "\n",
        "        # classifier layer to predict if same finger or not\n",
        "        self.fc =  nn.Sequential(\n",
        "            nn.Linear(256,1)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        # This function will be called for both images\n",
        "        # Its output is used to determine the similiarity\n",
        "        x = x.unsqueeze(1)\n",
        "        output = self.feature_extractor(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # In this function we pass in both images and obtain both vectors\n",
        "        # which are returned\n",
        "\n",
        "        # print(f\"Input1 shape before forward_once: {input1.shape}\")\n",
        "        # print(f\"Input2 shape before forward_once: {input2.shape}\")\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        # print(output1)\n",
        "\n",
        "        # get absolute difference of extracted features\n",
        "        output = torch.abs(output1 - output2)\n",
        "        output = self.fc(output).view(-1)\n",
        "\n",
        "        # return output1, output2\n",
        "        return output"
      ],
      "metadata": {
        "id": "70awOurJ0RcK"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new implementation with Pytorch Lightning, Weights and biases library\n",
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "_wLCKhx2QwaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "# wandb.finish()\n",
        "\n",
        "wandb_config = {\n",
        "    \"architecture\": \"Simple_CNN\",\n",
        "    \"datasets\": \"all\",\n",
        "    \"loss\": \"binary_cross_entropy\"\n",
        "}\n",
        "\n",
        "# hyperparameters tbd\n",
        "\n",
        "wandb_logger = WandbLogger(project=\"siamese_fingerprint\", config = wandb_config)\n",
        "# wandb.init(\n",
        "#     project=\"siamese-fingerprint\",\n",
        "#     config = wandb_config\n",
        "\n",
        "# )"
      ],
      "metadata": {
        "id": "d-e8En7kQ9XN"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning.pytorch as pl\n",
        "\n",
        "class CustomModule(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def get_acc(self, preds, labels):\n",
        "        output = (preds > 0.5).float()\n",
        "        correct = (output == labels).float().sum()\n",
        "\n",
        "        return correct / preds.shape[0]\n",
        "\n",
        "    def get_eucledian_acc(self, preds, labels):\n",
        "        output = (preds > 0.15).float()\n",
        "        correct = (output == labels).float().sum()\n",
        "\n",
        "        return correct / preds.shape[0]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x1, x2, y = batch\n",
        "        preds = self.model(x1, x2)\n",
        "        loss = torch.nn.functional.binary_cross_entropy_with_logits(preds, y.float())\n",
        "        self.train_acc = self.get_acc(torch.sigmoid(preds), y)\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", self.train_acc, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x1, x2, y = batch\n",
        "        preds = self.model(x1, x2)\n",
        "\n",
        "        # print(preds, y)\n",
        "        loss = nn.functional.binary_cross_entropy_with_logits(preds, y.float())\n",
        "        self.val_acc = self.get_acc(torch.sigmoid(preds), y)\n",
        "\n",
        "        self.val_loss = loss\n",
        "\n",
        "        self.log(\"val_loss\", self.val_loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.validation_step(batch, batch_idx)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        x1, x2 = batch\n",
        "        preds = self.model(x1, x2)\n",
        "\n",
        "        return torch.sigmoid(preds)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, factor=0.5, mode='min', verbose=True, patience=15, threshold=0)\n",
        "        return {\n",
        "           'optimizer': optimizer,\n",
        "           \"lr_scheduler\": {\n",
        "                \"scheduler\": lr_scheduler,\n",
        "                \"monitor\": \"val_loss\"}\n",
        "       }\n",
        "\n",
        "\n",
        "vgg = TorchVGG()\n",
        "\n",
        "VGG_BCE = CustomModule(vgg)\n",
        "\n",
        "mobile = SiameseNetwork_MobileNet()\n",
        "litmodel = CustomModule(mobile)\n",
        "\n"
      ],
      "metadata": {
        "id": "wwLcUkGWUlJC"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class DatasetType(enum.Enum):\n",
        "    TRAIN = 0\n",
        "    VAL = 1\n",
        "    TEST = 2\n",
        "\n",
        "class StaticFingerprintDataset(Dataset):\n",
        "    def __init__(self, dataset_type: DatasetType, transform=None):\n",
        "        self.dataset_type = dataset_type\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load testset.csv, trainset.csv, or valset.csv\n",
        "\n",
        "        if self.dataset_type == DatasetType.TRAIN:\n",
        "            file_path = \"/content/drive/My Drive/trainset.csv\"\n",
        "        elif self.dataset_type == DatasetType.VAL:\n",
        "            file_path = \"/content/drive/My Drive/valset.csv\"\n",
        "        elif self.dataset_type == DatasetType.TEST:\n",
        "            file_path = \"/content/drive/My Drive/testset.csv\"\n",
        "\n",
        "        self.csv = pd.read_csv(file_path)\n",
        "        # print(self.csv.columns)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.to_list()\n",
        "\n",
        "        img1_name = self.csv.iloc[idx, 0]\n",
        "        img2_name = self.csv.iloc[idx, 1]\n",
        "        label = self.csv.iloc[idx, 2]\n",
        "\n",
        "        img1_path = os.path.join(\"/content/drive/My Drive/fingerprints_combined\", img1_name)\n",
        "        img2_path = os.path.join(\"/content/drive/My Drive/fingerprints_combined\", img2_name)\n",
        "\n",
        "        # L is for black and white, RGB is for color\n",
        "        image1 = Image.open(img1_path).convert(\"L\")\n",
        "        image2 = Image.open(img2_path).convert(\"L\")\n",
        "\n",
        "        image1 = image1.resize((100, 100))\n",
        "        image2 = image2.resize((100, 100))\n",
        "\n",
        "        # Convert images to numpy arrays and change datatype to float32\n",
        "        image1 = np.array(image1, dtype=np.float32)\n",
        "        image2 = np.array(image2, dtype=np.float32)\n",
        "\n",
        "        label = self.csv.iloc[idx, 2]\n",
        "        # print(label)\n",
        "\n",
        "        # if self.transform:\n",
        "        #     image1 = self.transform(image1)\n",
        "        #     image2 = self.transform(image2)\n",
        "\n",
        "        return image1, image2, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = StaticFingerprintDataset(DatasetType.TRAIN)\n",
        "val_data = StaticFingerprintDataset(DatasetType.VAL)\n",
        "test_data = StaticFingerprintDataset(DatasetType.TEST)\n",
        "\n",
        "# train_data = StaticFingerprintDataset(DatasetType.TRAIN, transform=transform)\n",
        "# val_data = StaticFingerprintDataset(DatasetType.VAL, transform=transform)\n",
        "# test_data = StaticFingerprintDataset(DatasetType.TEST, transform=transform)\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "yQtQUeJ0skP0"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='val_loss',\n",
        "   min_delta=0.00,\n",
        "   patience=35,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "   dirpath=\"./checkpoints\",\n",
        "   monitor='val_loss',\n",
        "   filename='best'\n",
        ")\n",
        "\n",
        "# wandb.init(project=\"siamese-fingerprint\")\n",
        "\n",
        "trainer = pl.Trainer(accelerator='gpu', max_epochs=3000,\n",
        "                    #  logger=wandb_logger,\n",
        "                     callbacks=[early_stop_callback, checkpoint_callback])\n",
        "trainer.fit(model=litmodel, train_dataloaders=train_loader, val_dataloaders=val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "74ef19e5289e460d8fffc7e4fc65fe77",
            "8a1093d45b6d4b9885358d9c2fd194fa",
            "047159ead46f4b68b808406f4c2b2ad6",
            "d3dd3721f24b4de096a6cfb2646157e8",
            "8a46ce8796b44e289bc3659430242713",
            "61691e6ad2dc46a289e85c8095aca316",
            "6de1b06f57fb4afbb8b9b92bec82cde4",
            "3fe0a44815a8469188733c633c07d423",
            "a72de5e63084402bbadf34b05d22cb1a",
            "cf8f7ff90d7147cba37e2dd9fdae665d",
            "7a051e50ff21406abe60e5b82d23addf",
            "5aa3b65b72174126970621c8e1941be2",
            "1ed54a700a824facb72c443cfdc6e6f5",
            "424827fa93a14875a9f429c9d0c81b04",
            "b4a2db8a4a7d49c193a6cfec76d7b140",
            "ba401e22ce37456591305c475f89a9d6",
            "2be4681cdf34468da0ec87f717b066cf",
            "7e9d582ddb5047019d7abea8342907c1",
            "696eb13323f244b3a5580f569263a1cf",
            "ecd04956bbd1493682f7dac62bed1f44",
            "a6703ba0fd014953b8cab298951f1b47",
            "9a5b38489ef643ff930d84ea1fd59438"
          ]
        },
        "id": "Jb6sUTemq4oL",
        "outputId": "1320208b-75b8-4ddf-922a-7697ef577386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING: Missing logger folder: /content/drive/MyDrive/fingerprints_combined/lightning_logs\n",
            "WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/drive/MyDrive/fingerprints_combined/lightning_logs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name  | Type                     | Params\n",
            "---------------------------------------------------\n",
            "0 | model | SiameseNetwork_MobileNet | 1.8 M \n",
            "---------------------------------------------------\n",
            "1.8 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.8 M     Total params\n",
            "7.121     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type                     | Params\n",
            "---------------------------------------------------\n",
            "0 | model | SiameseNetwork_MobileNet | 1.8 M \n",
            "---------------------------------------------------\n",
            "1.8 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.8 M     Total params\n",
            "7.121     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74ef19e5289e460d8fffc7e4fc65fe77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "11\n",
            "\n",
            "1\n",
            "1\n",
            "1\n",
            "tensor([0.0171], device='cuda:0') tensor([1], device='cuda:0')\n",
            "tensor([0.0171], device='cuda:0') tensor([1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aa3b65b72174126970621c8e1941be2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "px-zYn3B1SxE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}